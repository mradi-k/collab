{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "UtOq7a7i6bL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "ATa4Z_IR8Gpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "aGrryk4A8cB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence = \"Tell me about space exploration.\"\n",
        "res = tokenizer(sequence)\n",
        "# print(res)\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "print(type(tokens))\n",
        "tokennn=tokens\n",
        "print(len(tokennn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFz7MJUx8TEH",
        "outputId": "22d741fc-8fec-4368-ad84-41e9a8169bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "input_prompt = \"Tell me about space exploration.\"\n",
        "generated_response = \"Space exploration has led to many discoveries...\"\n",
        "\n",
        "input_tokens = tokenizer.tokenize(input_prompt)\n",
        "response_tokens = tokenizer.tokenize(generated_response)\n",
        "\n",
        "total_tokens = len(input_tokens) + len(response_tokens) + 4  # +4 for [CLS], [SEP], [PAD], [UNK] if present\n",
        "\n",
        "print(input_tokens)\n",
        "print(response_tokens)\n",
        "print(\"Total tokens:\", total_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMkSNiJH_Lnx",
        "outputId": "dedb925a-bc02-46f7-b913-82e4b4296238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tell', 'Ġme', 'Ġabout', 'Ġspace', 'Ġexploration', '.']\n",
            "['Space', 'Ġexploration', 'Ġhas', 'Ġled', 'Ġto', 'Ġmany', 'Ġdiscoveries', '...']\n",
            "Total tokens: 18\n"
          ]
        }
      ]
    }
  ]
}